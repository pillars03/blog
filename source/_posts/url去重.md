---
title: url日志去重
date: 2018-02-06 05:37:10
tags:
---
去重

<!--more-->
现有一个5g的日志文件，里面保存的是URL，这写URL有重复的，怎么得到一个不重复的URL日志文件
去重比较简单，用URL做key生成一个字典就可以了，但是5g的文件字符串做一次处理，内存肯定爆掉了，所以应该先把5g的文件分成小文件，逐行读取按照，相同的字符串放到一个文件，将一个文件分解成若干个小文件。之后的工作比较简单了，不具体说了